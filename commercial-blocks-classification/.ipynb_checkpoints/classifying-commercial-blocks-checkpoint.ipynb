{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Commecial Blocks with Microsoft Azure\n",
    "_**Comparing Automated Machine Learning with three standard Scikit Learn Models.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "    1. [Accessing the Azure Workspace](#Accessing-the-Azure-Workspace)\n",
    "    1. [Configuring the Azure Workspace](#Configuring-the-Azure-Workspace)\n",
    "    1. [Importing Libraries](#Importing-Libraries)\n",
    "    1. [Creating an Experiment](#Creating-an-Experiment)\n",
    "1. [Data](#Data)\n",
    "1. [Classifying with Scikit Learn](#Classifying-with-Scikit-Learn)\n",
    "1. [Classifying with Automated Machine Learning](#Classifying-with-Automated-Machine-Learning)\n",
    "1. [Results](#Results)\n",
    "1. [Finding the Best Classification Model](#Finding-the-Best-Classification-Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**The Task:** Classify commercial blocks from TV news segments (+1 commercial, -1 Non-commercial).\n",
    "\n",
    "This classification model runs a dataset of broadcast data to classify whether a specific segment is a commercial on television. The dataset was taken from the UCI Machine Learning Repository with over 120,000 instances and 4125 features. For more information about the features in this datset, check out [the UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/tv+news+channel+commercial+detection+dataset). \n",
    "\n",
    "**The Method:** This experiment will compare training a classification model with traditional machine learning models (KNN, Random Forest, Neural Networks) to training it with Microsoft Azure Automated Machine Learning. \n",
    "\n",
    "<br>\n",
    "<img src=\"https://sportsradiopd.com/wp-content/uploads/2015/11/commercial-e1447279275378.jpg\" style=\"width:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment uses [Microsoft Azure Machine Learning Service](https://docs.microsoft.com/en-us/azure/machine-learning/service/) to implement a machine learning classification model. For more examples of Microsoft Machine Learning Service, check out the [Azure Machine Learning Notebooks GitHub Repo](https://github.com/Azure/MachineLearningNotebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Azure Workspace\n",
    "To configure a Microsoft Azure workspace, you must [set up a  Azure subscription](https://azure.microsoft.com/en-us/free/) and manage the subscription from the [Azure portal](https://portal.azure.com/). Once your workspace is configured in the Azure portal, your machine learning service workspace should look like the following:\n",
    "\n",
    "\n",
    "<img src=\"Images/Azure-Configuration.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the Azure Workspace\n",
    "Before configuring your workspace, be sure to have the following installed:\n",
    "```\n",
    "$ conda install -y matplotlib tqdm scikit-learn\n",
    "$ pip install azureml-sdk[notebooks,automl]\n",
    "```\n",
    "Then, add a `config.json` file in a directory two levels above anything that is being pushed to Github. **Never push your Subscription ID to Github**. Your Azure notebook will find the config file even if it is not in the present directory.\n",
    "\n",
    "`config.json` should look like the following (see above figure for where to find these inputs):\n",
    "```\n",
    "{\n",
    "    \"subscription_id\": \"<my-subscription-id>\",\n",
    "    \"resource_group\": \"<my-resource-group>\",\n",
    "    \"workspace_name\": \"<my-workspace-name>\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\house\\Documents\\GitHub\\config.json\n"
     ]
    }
   ],
   "source": [
    "# Now you're ready to load your workspace...\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# IMPORT AZURE LIBRARIES\n",
    "# Azure Notebook Libraries\n",
    "import azureml.core\n",
    "import logging\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Experiment\n",
    "This command will create a new experiment on Azure's Machine Learning Services Workspace. Experiments track important metrics of each model run, including training time (in seconds) and the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a name for the experiment and specify the project folder.\n",
    "experiment_name = 'simple_classification'\n",
    "project_folder = './simple_classification_project'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Azure-Experiments.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Data is from the UCI Machine Learning Repository with over 120,000 instances and 4125 features to [classify commercial blocks](http://archive.ics.uci.edu/ml/datasets/tv+news+channel+commercial+detection+dataset).\n",
    "\n",
    "Data Citation:\n",
    "Dr. Prithwijit Guha , Raghvendra D. Kannao and Ravishankar Soni \n",
    "Multimedia Analytics Lab, \n",
    "Department of Electrical and Electronics Engineering, \n",
    "Indian Institute of Technology, Guwahati, India \n",
    "rdkannao '@' gmail.com , prithwijit.guha '@' gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data from Local Directory\n",
    "To import this data, make sure to download the datasets in `Data/` on your local machine and point to your filepath in `get_data()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importing Data...\n",
      "Data imported.\n"
     ]
    }
   ],
   "source": [
    "# Data Upload Functions\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "def get_data(filepath):\n",
    "    data = load_svmlight_file(filepath)\n",
    "    return data[0], data[1]\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# IMPORT DATA\n",
    "print(\"\\nImporting Data...\")\n",
    "\n",
    "X_train, y_train = get_data(\"Data/train_data.txt\")\n",
    "X_test, y_test = get_data(\"Data/test_data.txt\")\n",
    "\n",
    "X_train = X_train.toarray() # convert sparce matrix to array\n",
    "X_test = X_test.toarray() \n",
    "print(\"Data imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying with SciKit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Dependencies\n",
    "This is a local run of the classifcation model, so you must ensure all the necessary packages are available in the Python environment you run in the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Editing a run configuration property on-fly.\n",
    "run_config_user_managed = RunConfiguration()\n",
    "\n",
    "run_config_user_managed.environment.python.user_managed_dependencies = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Local Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train.py', 'r') as f:\n",
    "    f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with `train.py` Script and Log Metrics\n",
    "With Azure, you can run a local `train.py` script. To track the accuracy in your local `train.py` script, you can add logger capabilities. With logging, Azure keeps track of any variable changes during training and plots the variables for you with the Azure Portal.\n",
    "\n",
    "To add logging, add the following lines to your `train.py`code:\n",
    "```\n",
    "from azureml.core.run import Run\n",
    "\n",
    "# Your training script goes here...\n",
    "\n",
    "# Run this script to initialize logger in your experiment context\n",
    "run_logger = Run.get_context()\n",
    "\n",
    "# Log any variable that you would like to track!\n",
    "run_logger.log(name='Accuracy', value=accuracy) \n",
    "run_logger.log(name='Training_Time', value=train_t) \n",
    "```\n",
    "[Navigate here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-track-experiments#viewing-charts-in-run-details) more information about logging variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "src = ScriptRunConfig(source_directory='./', script='train.py', run_config=run_config_user_managed)\n",
    "run = experiment.submit(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>simple_classification</td><td>simple_classification_1555074315_b61d4ca2</td><td>azureml.scriptrun</td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/a989cac4-671d-45c6-9d2b-ea7e9d936600/resourceGroups/AmherstRG/providers/Microsoft.MachineLearningServices/workspaces/AmherstWorkspace/experiments/simple_classification/runs/simple_classification_1555074315_b61d4ca2\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: simple_classification,\n",
       "Id: simple_classification_1555074315_b61d4ca2,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View your Evaluation Metrics in Azure\n",
    "Azure automatically visualizes your logged metrics for your convenience. This expermiment logs `Training_Time` and `Accuracy` for the default Random Forest, Neural Networks, K Nearest Neighbor models in SciKit Learn. \n",
    "\n",
    "**Click `Link to Azure Portal` above** to view your visualizations:\n",
    "\n",
    "<img src=\"Images/Azure-Logging-1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get your evaluation metrics as a dictionary, use the following commamd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': ['Random Forest', 'Neural Networks', 'K Nearest Neighbor'],\n",
       " 'Accuracy': [0.884, 0.785, 0.777],\n",
       " 'Training_Time': [2.26, 5.59, 0.17]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_metrics = run.get_metrics()\n",
    "run_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using well-known models in Scikit Learn, we only achieve up to ~88% accuracy on the test set with Random Forest classification. Let's store the best accuracy and see if Automated Machine Learning can beat our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Accuracy we acheived with Scikit Learn:  88.40%\n"
     ]
    }
   ],
   "source": [
    "best_manual_accuracy = float(max(run_metrics['Accuracy'])) * 100 \n",
    "print(\"The best Accuracy we acheived with Scikit Learn:  %.2f%%\" % best_manual_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying with Automated Machine Learning\n",
    "Microsoft Azure's [Automated Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train) functionality trains models for you to help find the best model for your machine learning problem. The following experiment will compare the metrics I achieved with the simple `train.py` script with the automated machine learning metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Automated ML for classification\n",
    "Automated ML offers many different configurations to match your machine learning task. [This article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train#select-your-experiment-type) describes all the possible configurations you can choose from. I decided to iterate through 10 different models with 3 cross validations to attempt to beat my initial 88% accuracy result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             primary_metric = 'AUC_weighted',\n",
    "                             iteration_timeout_minutes = 60,\n",
    "                             iterations = 10,\n",
    "                             n_cross_validations = 3,\n",
    "                             verbosity = logging.INFO,\n",
    "                             X = X_train, \n",
    "                             y = y_train,\n",
    "                             path = project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the AML Experiment Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_26005e4b-041d-4401-bfa6-ad42832bddad\n",
      "********************************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "SAMPLING %: Percent of the training data to sample.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "********************************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       SAMPLING %  DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          100.0000    0:00:19       0.9495    0.9495\n",
      "         1   RobustScaler LightGBM                          100.0000    0:00:21       0.9719    0.9719\n",
      "         2   RobustScaler LogisticRegression                100.0000    0:00:24       0.9401    0.9719\n",
      "         3   StandardScalerWrapper LightGBM                 100.0000    0:00:22       0.9579    0.9719\n",
      "         4   MaxAbsScaler LightGBM                          100.0000    0:00:27       0.9434    0.9719\n",
      "         5   MinMaxScaler LightGBM                          100.0000    0:00:21       0.9594    0.9719\n",
      "         6   StandardScalerWrapper LightGBM                 100.0000    0:00:18       0.9565    0.9719\n",
      "         7   MinMaxScaler LogisticRegression                100.0000    0:00:18       0.9399    0.9719\n",
      "         8   StandardScalerWrapper LightGBM                 100.0000    0:00:21       0.9338    0.9719\n",
      "         9   Ensemble                                       100.0000    0:00:32       0.9678    0.9719\n"
     ]
    }
   ],
   "source": [
    "local_run = experiment.submit(automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>simple_classification</td><td>AutoML_26005e4b-041d-4401-bfa6-ad42832bddad</td><td>automl</td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/a989cac4-671d-45c6-9d2b-ea7e9d936600/resourceGroups/AmherstRG/providers/Microsoft.MachineLearningServices/workspaces/AmherstWorkspace/experiments/simple_classification/runs/AutoML_26005e4b-041d-4401-bfa6-ad42832bddad\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: simple_classification,\n",
       "Id: AutoML_26005e4b-041d-4401-bfa6-ad42832bddad,\n",
       "Type: automl,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View your Machine Learning Performance in Azure\n",
    "To view the `Weighted AUC` of your experiment as a visualization, **Click `Link to Azure Portal` above**.\n",
    "\n",
    "<img src=\"Images/Azure-AutoML-1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ed3ebf1f0c41148bb59b08c186c19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(local_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the Best Auto ML Model\n",
    "Now the best classification model from the Automated Machine Learning iterations was selected to compare with the manual `train.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = local_run.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Best Classification Model\n",
    "Let's compare the testing accuracy of the manual training script versus the automated machine learning script to find the best classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train.py Accuracy: 88.40%\n",
      "Automated Machine Learning Accuracy: 91.65%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred = fitted_model.predict(X_test)\n",
    "aml_accuracy = f1_score(y_test, y_pred) * 100\n",
    "\n",
    "print('Train.py Accuracy: %.2f%%' % best_manual_accuracy)\n",
    "print('Automated Machine Learning Accuracy: %.2f%%' % aml_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using Automated Machine Learning, we increased our testing accuracy by 3.25%!\n",
    "\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/YJ5OlVLZ2QNl6/giphy.gif\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
